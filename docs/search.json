[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/post-on-gh/index.html",
    "href": "posts/post-on-gh/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "Git init on inside blog root &gt; point github pages to docs &gt; works in a second"
  },
  {
    "objectID": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html",
    "href": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html",
    "title": "Instructions",
    "section": "",
    "text": "---\ntitle: \"New Post\"\ndate: \"2025-02-06\"\nauthor: \"Alexander\"\ndescription: \"A nice new post\"\ncategories: [nonsense, code]\n---\nA note on group work:\nWe recommend that each group member attempts the solution to each exercise on their own at first, and then discusses it with the other member. Experience shows that in this way groups get more ideas for solutions and eventually write better code. Choose to work in a way that ensures each group member is able to solve each task on their own in the end."
  },
  {
    "objectID": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-0-matrix-manipulations-with-numpy",
    "href": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-0-matrix-manipulations-with-numpy",
    "title": "Instructions",
    "section": "Exercise 0: Matrix manipulations with numpy",
    "text": "Exercise 0: Matrix manipulations with numpy\nConsider the following matrices:\n$ A =\n\\[\\begin{pmatrix}\n1 & 2 & 3\\\\\n4 & 5 & 6\\\\\n7 & 8 & 9\n\\end{pmatrix}\\]\n$ , $ B =\n\\[\\begin{pmatrix}\n11 & 12 & 13\\\\\n14 & 15 & 16\\\\\n17 & 18 & 19\n\\end{pmatrix}\\]\n$ and $ C =\n\\[\\begin{pmatrix}\n1 & 2\\\\\n3 & 4\\\\\n5 & 6\n\\end{pmatrix}\\]\n$\n\nTask 1\nUse numpy and the above matrices to: - perform one matrix addition - perform one element-wise matrix multiplication - perform one matrix multiplication - concatenate the matrices \\(A\\) and \\(C\\) along their columns and print the result. The resulting matrix’s dimension should be \\(3\\times5\\). - for each operation, print the resulting matrix dimension using the .shape method.\n\n\nTask 2\n\nExplain the requirements on the matrix dimensions for the three types of operations performed in task 1.\n\n\n# YOUR CODE HERE\nimport numpy as np \nA = np.arange(1,10)\nA.resize((3,3))\n\nB = np.arange(11,20)\nB.resize((3,3))\n\nC = np.arange(1,7)\nC.resize((3,2))\n\nprint('A = ', A,'\\n','B = ',  B)\nprint('C =', C)\n\nprint('--- operations ---')\nprint('+', A+B, 'shape=',(A+B).shape)\nprint('dot', np.dot(A,B), 'shape=', (np.dot(A,B)).shape)\nprint('matmul', A@B, 'shape=', (A@B).shape)\nprint('concat', np.concatenate((A,C), axis=1), 'shape=', np.concatenate((A,C), axis=1).shape)\n\nA =  [[1 2 3]\n [4 5 6]\n [7 8 9]] \n B =  [[11 12 13]\n [14 15 16]\n [17 18 19]]\nC = [[1 2]\n [3 4]\n [5 6]]\n--- operations ---\n+ [[12 14 16]\n [18 20 22]\n [24 26 28]] shape= (3, 3)\ndot [[ 90  96 102]\n [216 231 246]\n [342 366 390]] shape= (3, 3)\nmatmul [[ 90  96 102]\n [216 231 246]\n [342 366 390]] shape= (3, 3)\nconcat [[1 2 3 1 2]\n [4 5 6 3 4]\n [7 8 9 5 6]] shape= (3, 5)"
  },
  {
    "objectID": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-1-condition-number",
    "href": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-1-condition-number",
    "title": "Instructions",
    "section": "Exercise 1: Condition number",
    "text": "Exercise 1: Condition number\nIn this exercise you will explore the sensitivity of a solution of a linear system of equations to numerical errors.\nConsider the matrices:\n$ A =\n\\[\\begin{pmatrix}\n0.8647 & 0.5766\\\\\n0.4322 & 0.2822\n\\end{pmatrix}\\]\n$\nand\n$ M =\n\\[\\begin{pmatrix}\n8.5 & 1.5\\\\\n1.8 & 3.1\n\\end{pmatrix}\\]\n$\n\nTask 1.\nWrite a python function that computes the condition number of a matrix, as defined in the lecture on systems of linear equations. Recall the definition of the condition number for a matrix \\(A\\) as: \\(\\|A\\|  \\|A^{-1}\\|\\). For a square matrix of dimension \\(n\\), we have \\(\\|A\\| = \\sqrt{\\sum_{1\\le i, j \\le n} A_{ij}^2}\\) (the square root of the sum of the square of each element).\nIn your implementation of the python function: - Use np.linalg.norm or write a custom function for calculating the norm of a matrix. - Use numpy.linalg.inv for inverting the matrix.\nApply your function to the matrices \\(A\\) and \\(M\\) and print out the result.\n\n\nTask 2.\nWrite a python function that adds a small perturbation to the element in the first row and first column of a matrix.\nApply your function to the matrices \\(A\\) and \\(M\\) using a perturbation of \\(p=0.0001\\), creating new (perturbed) matrices \\(A'\\) and \\(M'\\).\n\n\nTask 3.\nConsider the vector $ b =\n\\[\\begin{pmatrix}\n0.2885 \\\\\n0.1442\n\\end{pmatrix}\\]\n$.\nUse numpy.linalg.solve to solve the systems: - \\(Ax = b\\) - \\(A'x = b\\) - \\(Mx = b\\) - \\(M'x=b\\)\nwhere \\(x\\) is an unknown vector.\n\n\nTask 4.\n\nMeasure in any way you like the difference between the solutions for \\(x\\) you found in the first two cases of task 3, and the difference between the solutions found for the last two cases of task 3.\nExplain why these results could be expected based on the condition number.\n\n\n# YOUR CODE HERE\n# Task 1 \nimport numpy as np \nA = np.array(\n    [[0.8647, 0.5766], \n    [0.4322, 0.2822]\n])\n\nM = np.array([\n    [8.5, 1.5],\n    [1.8, 3.1]\n])\n\nnp_conumber = np.linalg.norm(A)\nmat_conumber= np.sqrt(np.sum(np.power(A.reshape(1,-1),2)))  # messy but accurate\nnopy_conumber = np.sum(A.reshape(1,-1)**2)**0.5  # same result less convulated\n# print(np_conumber - mat_conumber)\n# print(nopy_conumber - np_conumber)\n\ndef cond_number(A):\n    \"\"\"Conditional number for matrix A\n\n    Args:\n        A (np.array like): _description_\n    \"\"\"\n    A = np.array(A)\n    norm = np.linalg.norm(A)\n    inv_A = np.linalg.norm(np.linalg.inv(A))\n    return norm*inv_A, norm*inv_A - np.linalg.cond(A)  # second term error\n\nprint('Task 1 A:')\nprint('our cond', cond_number(A)[0])\nprint('np cond\\t', np.linalg.cond(A))\nprint('diff: \\t', cond_number(A)[1])\nprint()\nprint('M:')\nprint('our cond', cond_number(M)[0])\nprint('np cond\\t', np.linalg.cond(M))\nprint('diff: \\t', cond_number(M)[1])\n\n\n# Task 2 \ndef perturb_first(A):\n    \"\"\"perturbs the first element with p = 0.0001\n\n    Args:\n        A (np.array like): _description_\n    \"\"\"\n    p = 0.0001\n    B = A.copy()  # design choice, otherwise destructive for matrix A (read next comment)\n    B[0,0] += p\n    return B\n    \nB = A.copy()  # important to copy, otherwise stores the reference\n\nAp = perturb_first(A) \nMp = perturb_first(M)\nprint()\nprint(\"Task 2: First Ap - A, second Mp - M \")\nprint(Ap - A)\nprint(Mp - M)\n\n\n# Task 3 \nb = np.array([\n    [0.2885],\n    [0.1442]\n])\nprint()\nprint('Task 3: solve for x')\nprint('x0 = ', np.linalg.solve(A,b).reshape(1,-1))\nprint('x1 = ', np.linalg.solve(Ap,b).reshape(1,-1))\nprint('x2 = ', np.linalg.solve(M,b).reshape(1,-1))\nprint('x3 = ', np.linalg.solve(Mp,b).reshape(1,-1))\n\n\n# Task 4 \nprint()\nprint('Task 4')\nAxdiff = np.linalg.solve(A,b) - np.linalg.solve(Ap,b)\nMxdiff = np.linalg.solve(M,b) - np.linalg.solve(Mp, b)\n\nprint('x diff A-Ap', Axdiff.reshape(1,-1), cond_number(A)[0])  # greater than for M \nprint('x diff M-Mp', Mxdiff.reshape(1,-1), cond_number(M)[0])  # very low\n\nmagnitudediff = np.linalg.norm(Axdiff)/np.linalg.norm(Mxdiff)  # factor difference right way?\nprint('The difference in magnitude of norm(A-Ap)/norm(M-Mp): ', magnitudediff)\nprint('The difference in magnitude of cond(A)/cond(M): ', cond_number(A)[0]/cond_number(M)[0])\nprint('Seems like weird comparison, point is cond(A) &gt;&gt; cond(M), which infer that higher conditional number will change more with pertubations.')\n\n\n\n\nTask 1 A:\nour cond 259.55293185664556\nnp cond  259.5490790207813\ndiff:    0.0038528358642793137\n\nM:\nour cond 3.6934460887949254\nnp cond  3.399264832147035\ndiff:    0.2941812566478905\n\nTask 2: First Ap - A, second Mp - M \n[[1.e-04 0.e+00]\n [0.e+00 0.e+00]]\n[[1.e-04 0.e+00]\n [0.e+00 0.e+00]]\n\nTask 3: solve for x\nx0 =  [[ 3.33646867e-01 -7.70983274e-06]]\nx1 =  [[ 0.33547159 -0.00280235]]\nx2 =  [[0.02867019 0.02986892]]\nx3 =  [[0.02866981 0.02986914]]\n\nTask 4\nx diff A-Ap [[-0.00182473  0.00279464]] 259.55293185664556\nx diff M-Mp [[ 3.75798837e-07 -2.18205776e-07]] 3.6934460887949254\nThe difference in magnitude of norm(A-Ap)/norm(M-Mp):  7680.508529633639\nThe difference in magnitude of cond(A)/cond(M):  70.2739191575234\nSeems like weird comparison, point is cond(A) &gt;&gt; cond(M), which infer that higher conditional number will change more with pertubations."
  },
  {
    "objectID": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-2-matrix-inversion-using-lu-decomposition",
    "href": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-2-matrix-inversion-using-lu-decomposition",
    "title": "Instructions",
    "section": "Exercise 2: Matrix inversion using LU decomposition",
    "text": "Exercise 2: Matrix inversion using LU decomposition\nThis exercise guides you to create a python function for matrix inversion based on the LU decomposition method introduced in the lectures. You will test your function on the matrix:\n$ A =\n\\[\\begin{pmatrix}\n2 & 1 & 1\\\\\n1 & 1 & -2\\\\\n1 & 2 & 1\n\\end{pmatrix}\\]\n$.\n\nTask 1: Add functions to a module\n\nFrom sections 4.3.1 and 4.3.3 of the book Numerical Methods in Physics with Python find python functions for:\n\nforward substitution\nbackward substitution\nLU decomposition\nsolving \\(A x = b\\) via LU decomposition\n\nCopy-paste these functions into a new module named linalg.py.\nAdd a docstring to each of the functions in your module.\nCheck that the functions import correctly here.\n\nHint: There are electronic versions of the book that you can access via the Chalmers library.\n\n\nTask 2: Show with a coding example that a matrix can be inverted using LU decomposition\nBackground:\nRecall that \\(AA^{-1} = I\\), where \\(I\\) is the identity matrix. Let \\(x_i\\) and \\(e_i\\) be the column-vectors of \\(A^{-1}\\) and \\(I\\), respectively. Assume that the dimension of \\(A\\) is \\(n\\) x \\(n\\). Then:\n\\(A^{-1} = \\begin{pmatrix} x_0 & x_1 & ... & x_i & ... & x_{n-1}\\end{pmatrix}\\) and \\(I = \\begin{pmatrix} e_0 & e_1 & ... & e_i & ... & e_{n-1}\\end{pmatrix}\\)\nThus, inverting \\(A\\) means to solve equation \\(Ax_i = e_i\\), i.e. find \\(x_i\\).\nSince \\(A = LU\\), you can rewrite \\(Ax_i = e_i\\) as \\(L(Ux_i) = e_i\\).\nImplementation: - Create a python function that inverts a matrix via LU decomposition. - Use functions from task 1 to LU decompose the matrix A, namely to find \\(L\\) and \\(U\\) such as \\(A = LU\\). - Compare your inverted matrix with the inverted matrix returned by the numpy function numpy.linalg.inv and show that they closely agree.\nHint: you need to solve \\(Ly_i = e_i\\). Once \\(y_i\\) is known, then proceed with solving \\(Ux_i = y_i\\) and build \\(A^{-1}\\).\n\n\nTask 3: A different check\n\nPropose and implement another way to show that your inversion works (think about the equation satisfied by an inverse matrix).\n\n\n# YOUR CODE HERE\n# Task 1\nimport linalg, numpy as np \nA = np.array([\n    [2, 1, 1],\n    [1, 1,-2],\n    [1, 2, 1],\n])\n\nb = A[0,:].copy()\n\n# linalg.forward_sub(A, A[0,:])\nL, U = linalg.ludecomp(A)\n\nprint(linalg.lusolve(A, b), np.linalg.solve(A, b), 'ok lusolve, task 1')\n\ny = np.linalg.solve(L,b)\nx = np.linalg.solve(U,y)\n# print(x,y)  # my lusolve is not right &gt;&gt; now it works ()\n\n# Task 2 \ndef luinv(A):\n    I = np.eye(A[0].size)\n    L, U = linalg.ludecomp(A)\n\n    Ainv = np.zeros((A[0].size,A[0].size))\n    for i in range(I[0].size):\n        yi = linalg.forward_sub(L,I[i])\n        xi = linalg.backward_sub(U,yi)\n        Ainv[:,i] = xi\n    return Ainv\n  \n\nAinv = luinv(A)\nprint(Ainv)\nprint(np.linalg.inv(A)- Ainv)  # identical on my machine\n\n# Task 3 Alternative verification\nnp.linalg.det(Ainv)*np.linalg.det(A)  # = 1 per definition, thus works det(Ainv) = 1 / det(A), definition \n\n[1. 0. 0.] [ 1.  0. -0.] ok lusolve, task 1\n[[ 0.625  0.125 -0.375]\n [-0.375  0.125  0.625]\n [ 0.125 -0.375  0.125]]\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n\n\n1.0"
  },
  {
    "objectID": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-3-laser-tracking-equipment",
    "href": "posts/linalg-numpy/SEE125_Assignment3_SysLinEq_Group37.html#exercise-3-laser-tracking-equipment",
    "title": "Instructions",
    "section": "Exercise 3: Laser tracking equipment",
    "text": "Exercise 3: Laser tracking equipment\nA room is equipped with two lasers that aim at tracking the position of a person walking in it. Each laser follows the person. The equipment setup returns the equation of the ray of each laser (the line that connects the laser to the person). The laser rays move only in a plane parallel to the floor of the room (the distance from the floor is irrelevant).\nWe are interested in the position of the person, that is, the position where the two lasers intersect. At first, the two lasers are rather close to each other (just 10 cm apart).\n\nTask 1.\nYou are given the following starter code that creates a figure representing the room as seen from above, and the positions of the two laser rays.\nAs explained, the two lasers follow the person in the room, so the person is at the intersection of the two rays.\n\nWrite the system of linear equations that needs to be solved to compute the coordinates of the intersection (= the position of the person tracked).\nThen use np.linalg.solve to get the person’s coordinates and print them out.\nOn the same figure, add a black dot where the person is located and complete the legend.\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the x axis\nstep = 0.1\nx = np.arange(0,10+step,step)\n\n# Lasers sources positions:\ns1x, s1y = 2., 0 # laser_1\ns2xa, s2ya = 1.9, 0 # laser_2 position a\n\n# Equation for each laser\na1, b1 = 1., -2  # laser_1\na2a, b2a = 4/4.1, 4-24/4.1  # laser_2\ny1 = a1*x +b1\ny2a = a2a*x + b2a\n\n# Figure of the room with each laser position and their rays toward the person being tracked\n# The room is 10x10 m sides and seen from above. \n# The position (0,0) is the lower left corner of the room\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\nax.plot(s1x, s1y, 'r*', label='Laser source 1', markersize=10)\nax.plot(s2xa, s2ya, 'b*', label='Laser source 2a', markersize=10)\n\n\n# Plot the rays from each laser source\nax.plot(x, y1,'r')\nax.plot(x, y2a,'b')\n\nax.set_xlabel('x (m)')\nax.set_ylabel('y (m)')\nax.set_xlim([0, 10])\nax.set_ylim([0, 10])\nax.set_title('Sensors configuration a')\n\n\n\n\n#### YOUR CODE HERE\n# Task 1 \nA = np.array([\n    [a1, -1],\n    [a2a, -1],\n])\n\nb = np.array([\n    [-b1, -b2a]\n])\n\nisect = np.linalg.solve(A,b.T)\nplt.plot(isect[0], isect[1], marker='o', label='intersection', color='black')\n\n\nax.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\n\nTask 2.\nLike any real sensor, some measurement uncertainties will leak into the laser equation. - To mimic these uncertainties, let’s apply a small perturbation p = 0.001 on the two slope coefficients: \\(a1 + p\\) and \\(a2a - p\\) and solve the system again. - Compute the distance between the position in task 1 and the one found here. - Could you have expected this sensitivity to uncertainties? Justify quantitatively (with numbers). - Explain intuitively why this occurs.\n\n# YOUR CODE HERE\np = 0.001\n\nAp = A.copy()\nAp[0,0] = a1 + p \nAp[1,0] = a2a - p \n\nisect2 = np.linalg.solve(A,b.T)\n\nprint(isect.T, isect2.T)\nprint(f'Distance to pertubation: {np.linalg.norm(isect - isect2):.4f} m')\n\nprint('The conditional number is quite high for A, so sensitivity is not surprising. Did get lower for new pertubed matrix')\nprint('cond(A):', cond_number(A)[0], cond_number(Ap)[0])\nprint('Inuitively we have two laser close to each other targeting same point a distance relatively far way. Thus changes to slope affect the intersection.')\n\n[[6. 4.]] [[6. 4.]]\nDistance to pertubation: 0.0000 m\nThe conditional number is quite high for A, so sensitivity is not surprising. Did get lower for new pertubed matrix\ncond(A): 162.024390243903 149.74720170416236\nInuitively we have two laser close to each other targeting same point a distance relatively far way. Thus changes to slope affect the intersection.\n\n\n\n\nTask 3.\nAbove we saw what it practically means to have an ill-conditioned problem. A bad setting in a physical system leads to numerical issues.\nOne solution is to move one of the lasers. We will move the second laser source further away along the same wall. It’s new position is now: \\(x, y = 8, 0\\). The laser source 1 stays at the same place as before.\n\nMake a figure of the new configuration and laser rays.\nCompute and print the person’s position\nApply the same perturbation p = 0.001 on the two slope coefficients: \\(a1 + p\\) and \\(a2b - p\\) and solve the system again. Do you have a more robust system, why? (give numbers)\nOn the same figure, add a black dot where the person is located and complete the legend.\n\n\n# YOUR CODE HERE\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Define the x axis\nstep = 0.1\nx = np.arange(0,10+step,step)\n\n# Lasers sources positions:\ns1x, s1y = 2., 0 # laser_1\ns2xa, s2ya = 8, 0 # laser_2 position a\n\n# Equation for each laser\na1, b1 = 1., -2  # laser_1\na2a, b2a = -3/2, 12  # laser_2\ny1 = a1*x +b1\ny2a = a2a*x + b2a\n\n# Figure of the room with each laser position and their rays toward the person being tracked\n# The room is 10x10 m sides and seen from above. \n# The position (0,0) is the lower left corner of the room\nfig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 5))\nax.plot(s1x, s1y, 'r*', label='Laser source 1', markersize=10)\nax.plot(s2xa, s2ya, 'b*', label='Laser source 2a', markersize=10)\n\n\n# Plot the rays from each laser source\nax.plot(x, y1,'r')\nax.plot(x, y2a,'b')\n\nax.set_xlabel('x (m)')\nax.set_ylabel('y (m)')\nax.set_xlim([0, 10])\nax.set_ylim([0, 10])\nax.set_title('Sensors configuration a')\n\n\n\n\n#### YOUR CODE HERE\n# Task 1 \nA = np.array([\n    [a1, -1],\n    [a2a, -1],\n])\n\nb = np.array([\n    [-b1, -b2a]\n])\n\nisect = np.linalg.solve(A,b.T)\nplt.plot(isect[0], isect[1], marker='o', label='intersection*', color='black')\n\n\nax.legend()\nplt.show()\n\np = 0.001\n\nAp = A.copy()\nAp[0,0] = a1 + p \nAp[1,0] = a2a - p \n\nisect2 = np.linalg.solve(A,b.T)\n\nprint('intersection before/after perturbed:', isect.T, isect2.T)\nprint(f'Distance to pertubation: {np.linalg.norm(isect - isect2):.4f} m')  # already see much moer stable \nprint('cond(A):', cond_number(A)[0])\nprint('Just by moving the laser we get more stable experiment and are not peturbed! :) ')\n\n\n\n\n\n\n\n\nintersection before/after perturbed: [[5.6 3.6]] [[5.6 3.6]]\nDistance to pertubation: 0.0000 m\ncond(A): 2.1\nJust by moving the laser we get more stable experiment and are not peturbed! :)"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "posts/eigenvectors/index.html",
    "href": "posts/eigenvectors/index.html",
    "title": "Intuitive Eigenvectors, Eigenfunctions and Eigenvalues",
    "section": "",
    "text": "Three blue one brown on Eigenvectors.\nFirst establish vector framework with numpy. Solve linear systems \\(Ax = b\\) numerically. After understand the solve method I will put in intuition for eigen vectors\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Alexander’s (very technical) blog",
    "section": "",
    "text": "Instructions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 3, 2025\n\n\nAlexander\n\n\n\n\n\n\n\n\n\n\n\n\nIntuitive Eigenvectors, Eigenfunctions and Eigenvalues\n\n\n\n\n\n\nmath\n\n\n\n\n\n\n\n\n\nFeb 3, 2025\n\n\nAlexander\n\n\n\n\n\n\n\n\n\n\n\n\nPost With Code\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\nFeb 3, 2025\n\n\nAlexander\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nJan 31, 2025\n\n\nAlexander\n\n\n\n\n\n\nNo matching items"
  }
]